# google_rank_tracker.py

import logging
import random
import time
import urllib.parse
from datetime import datetime
import pandas as pd # Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø³Ø§Ø²ÛŒ Ù†ØªØ§ÛŒØ¬ Ø¯Ø± Ø§Ù†ØªÙ‡Ø§ÛŒ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª

try:
    from selenium import webdriver
    from selenium.webdriver.common.by import By
    from selenium.webdriver.common.keys import Keys
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException
    from selenium.webdriver.chrome.service import Service as ChromeService # Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ø¨Ù‡ØªØ± Ø¯Ø±Ø§ÛŒÙˆØ±
    # from webdriver_manager.chrome import ChromeDriverManager # Ø±Ø§Ù‡ Ø¯ÛŒÚ¯Ø± Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ø®ÙˆØ¯Ú©Ø§Ø± Ø¯Ø±Ø§ÛŒÙˆØ±
except ImportError:
    print("Ø®Ø·Ø§: Ù„Ø·ÙØ§Ù‹ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù„Ø§Ø²Ù… Ø±Ø§ Ù†ØµØ¨ Ú©Ù†ÛŒØ¯. `pip install selenium pandas openpyxl`")
    exit()

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ØµÙ„ÛŒ Ø±Ø¨Ø§Øª (Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø§ÛŒÙ†Ø¬Ø§ Ø±Ø§ ÙˆÛŒØ±Ø§ÛŒØ´ Ú©Ù†Ù†Ø¯) ---
TARGET_DOMAIN = "wikipedia.org"  # Ø¯Ø§Ù…Ù†Ù‡ ÙˆØ¨â€ŒØ³Ø§ÛŒØª Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø´Ù…Ø§ (Ø¨Ø¯ÙˆÙ† http ÛŒØ§ www)
KEYWORDS_TO_TRACK = [
    "Ù¾Ø§ÛŒØªÙˆÙ† (Ø²Ø¨Ø§Ù† Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ)", 
    "ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ†", 
    "Ú¯ÙˆÚ¯Ù„",
    "Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ú†ÛŒØ³Øª" # ÛŒÚ© Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ Ú©Ù‡ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø±ØªØ¨Ù‡ Ø®ÙˆØ¨ÛŒ Ù†Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ Ø¨Ø±Ø§ÛŒ ØªØ³Øª "Not Found"
]
MAX_PAGES_TO_CHECK = 3  # Ø­Ø¯Ø§Ú©Ø«Ø± ØªØ¹Ø¯Ø§Ø¯ ØµÙØ­Ø§Øª Ù†ØªØ§ÛŒØ¬ Ú¯ÙˆÚ¯Ù„ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ø± Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ
RESULTS_PER_PAGE_ESTIMATE = 10 # ØªØ®Ù…ÛŒÙ†ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø±ØªØ¨Ù‡ Ú©Ù„ÛŒ (Ú¯ÙˆÚ¯Ù„ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ú©Ù…ØªØ± ÛŒØ§ Ø¨ÛŒØ´ØªØ± Ù†Ø´Ø§Ù† Ø¯Ù‡Ø¯)

# Ù…Ø³ÛŒØ± ChromeDriver:
# 1. Ø§Ú¯Ø± ChromeDriver Ø¯Ø± PATH Ø³ÛŒØ³ØªÙ… Ø´Ù…Ø§ Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ø¯ØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§ÛŒÙ† Ø±Ø§ Ø®Ø§Ù„ÛŒ Ø¨Ú¯Ø°Ø§Ø±ÛŒØ¯ ÛŒØ§ Ø±ÙˆÛŒ None ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯.
#    (Selenium 4.6.0 Ùˆ Ø¨Ø§Ù„Ø§ØªØ± Ø¨Ù‡ ØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø± Ø³Ø¹ÛŒ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª ChromeDriver Ø¯Ø§Ø±Ø¯ Ø§Ú¯Ø± Ø¯Ø± PATH Ù†Ø¨Ø§Ø´Ø¯)
# 2. Ù…Ø³ÛŒØ± Ú©Ø§Ù…Ù„ ÙØ§ÛŒÙ„ Ø§Ø¬Ø±Ø§ÛŒÛŒ ChromeDriver Ø±Ø§ Ù…Ø´Ø®Øµ Ú©Ù†ÛŒØ¯ØŒ Ù…Ø«Ø§Ù„:
#    CHROME_DRIVER_PATH = "C:/WebDriver/chromedriver.exe" # Ø¨Ø±Ø§ÛŒ ÙˆÛŒÙ†Ø¯ÙˆØ²
#    CHROME_DRIVER_PATH = "/usr/local/bin/chromedriver"   # Ø¨Ø±Ø§ÛŒ Ù…Ú©/Ù„ÛŒÙ†ÙˆÚ©Ø³
CHROME_DRIVER_PATH = None # ØªÙˆØµÛŒÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Selenium Manager (Ø§Ø² Ù†Ø³Ø®Ù‡ Û´.Û¶ Ø¨Ù‡ Ø¨Ø¹Ø¯)

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´Ø±ÙØªÙ‡ (Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ ØªØºÛŒÛŒØ± Ù†ÛŒØ³Øª)
DEFAULT_USER_AGENT = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36" # ÛŒÚ© User-Agent Ù…Ø¹Ù‚ÙˆÙ„
RANDOM_DELAY_BETWEEN_KEYWORDS = (5, 10)  # ØªØ§Ø®ÛŒØ± ØªØµØ§Ø¯ÙÛŒ (Ø«Ø§Ù†ÛŒÙ‡) Ø¨ÛŒÙ† Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ø± Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ
RANDOM_DELAY_BETWEEN_PAGES = (2, 5)    # ØªØ§Ø®ÛŒØ± ØªØµØ§Ø¯ÙÛŒ (Ø«Ø§Ù†ÛŒÙ‡) Ø¨ÛŒÙ† Ù¾ÛŒÙ…Ø§ÛŒØ´ ØµÙØ­Ø§Øª Ù†ØªØ§ÛŒØ¬
IMPLICIT_WAIT_TIME = 10 # Ø­Ø¯Ø§Ú©Ø«Ø± Ø²Ù…Ø§Ù† (Ø«Ø§Ù†ÛŒÙ‡) Ø¨Ø±Ø§ÛŒ Ø§Ù†ØªØ¸Ø§Ø± Ø¶Ù…Ù†ÛŒ Ù‡Ù†Ú¯Ø§Ù… ÛŒØ§ÙØªÙ† Ø§Ù„Ù…Ø§Ù†
EXPLICIT_WAIT_TIME = 15 # Ø­Ø¯Ø§Ú©Ø«Ø± Ø²Ù…Ø§Ù† (Ø«Ø§Ù†ÛŒÙ‡) Ø¨Ø±Ø§ÛŒ Ø§Ù†ØªØ¸Ø§Ø± ØµØ±ÛŒØ­ Ø¨Ø±Ø§ÛŒ Ø§Ù„Ù…Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ø®Ø§Øµ
TAKE_SCREENSHOTS_ON_ERROR = True # Ú¯Ø±ÙØªÙ† Ø§Ø³Ú©Ø±ÛŒÙ†â€ŒØ´Ø§Øª Ø¯Ø± ØµÙˆØ±Øª Ø¨Ø±ÙˆØ² Ø®Ø·Ø§Ù‡Ø§ÛŒ Ù…Ù‡Ù…
LOG_LEVEL = logging.INFO # Ø³Ø·Ø­ Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ: DEBUG, INFO, WARNING, ERROR, CRITICAL
OUTPUT_FILENAME_PREFIX = "google_rank_report"
# --- Ù¾Ø§ÛŒØ§Ù† Ø¨Ø®Ø´ ØªÙ†Ø¸ÛŒÙ…Ø§Øª ---

# Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ
logging.basicConfig(level=LOG_LEVEL,
                    format='%(asctime)s - %(levelname)s - %(module)s - %(message)s',
                    datefmt='%Y-%m-%d %H:%M:%S')

class GoogleRankTracker:
    def __init__(self, driver_path=None, target_domain="", user_agent=None):
        self.driver_path = driver_path
        if not target_domain:
            raise ValueError("Ø¯Ø§Ù…Ù†Ù‡ Ù‡Ø¯Ù (target_domain) Ù†Ø¨Ø§ÛŒØ¯ Ø®Ø§Ù„ÛŒ Ø¨Ø§Ø´Ø¯.")
        self.target_domain = target_domain.lower().replace("www.", "").replace("http://", "").replace("https://", "")
        self.user_agent = user_agent or DEFAULT_USER_AGENT
        self.driver = None
        self._setup_driver()

    def _get_webdriver_options(self):
        """ØªÙ†Ø¸ÛŒÙ…Ø§Øª ChromeOptions Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯."""
        chrome_options = webdriver.ChromeOptions()
        chrome_options.add_argument(f"user-agent={self.user_agent}")
        chrome_options.add_argument("--headless")  # Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø¯ÙˆÙ† Ù†Ù…Ø§ÛŒØ´ Ù…Ø±ÙˆØ±Ú¯Ø±
        chrome_options.add_argument("--disable-gpu") # Ú¯Ø§Ù‡ÛŒ Ø¨Ø±Ø§ÛŒ headless Ù„Ø§Ø²Ù… Ø§Ø³Øª
        chrome_options.add_argument("--no-sandbox") # Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ø±ÙˆÛŒ Ù„ÛŒÙ†ÙˆÚ©Ø³ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø±ÙˆØª (Ø¨Ø§ Ø§Ø­ØªÛŒØ§Ø·)
        chrome_options.add_argument("--disable-dev-shm-usage") # Ø¨Ø±Ø§ÛŒ Ø±ÙØ¹ Ù…Ø´Ú©Ù„Ø§Øª Ø­Ø§ÙØ¸Ù‡ Ø§Ø´ØªØ±Ø§Ú©ÛŒ Ø¯Ø± Ú©Ø§Ù†ØªÛŒÙ†Ø±Ù‡Ø§ÛŒ Ø¯Ø§Ú©Ø±
        chrome_options.add_argument("--lang=en-US,en;q=0.9") # Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ù†ØªØ§ÛŒØ¬ Ø¨Ù‡ Ø²Ø¨Ø§Ù† Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø¨Ø±Ø§ÛŒ ÛŒÚ©Ø³Ø§Ù† Ø³Ø§Ø²ÛŒ Ø³Ø§Ø®ØªØ§Ø±
        chrome_options.add_argument("--blink-settings=imagesEnabled=false") # ØºÛŒØ±ÙØ¹Ø§Ù„ Ú©Ø±Ø¯Ù† Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØµØ§ÙˆÛŒØ± Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª Ø¨ÛŒØ´ØªØ±
        # chrome_options.add_argument("--proxy-server=ip:port") # Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù¾Ø±ÙˆÚ©Ø³ÛŒ
        # prefs = {"profile.managed_default_content_settings.cookies": 2} # Ø¨Ù„Ø§Ú© Ú©Ø±Ø¯Ù† Ú©ÙˆÚ©ÛŒ Ù‡Ø§ (Ù…ÛŒ ØªÙˆØ§Ù†Ø¯ Ù…Ù†Ø¬Ø± Ø¨Ù‡ Ú©Ù¾Ú†Ø§ Ø´ÙˆØ¯)
        # chrome_options.add_experimental_option("prefs", prefs)
        return chrome_options

    def _setup_driver(self):
        """Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ WebDriver."""
        try:
            options = self._get_webdriver_options()
            if self.driver_path:
                service = ChromeService(executable_path=self.driver_path)
                self.driver = webdriver.Chrome(service=service, options=options)
            else:
                # Selenium 4.6+ Ø§Ø² Selenium Manager Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ø®ÙˆØ¯Ú©Ø§Ø± Ø¯Ø±Ø§ÛŒÙˆØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
                logging.info(" Ù…Ø³ÛŒØ± ChromeDriver Ù…Ø´Ø®Øµ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª. ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Selenium Manager...")
                self.driver = webdriver.Chrome(options=options)
            
            self.driver.implicitly_wait(IMPLICIT_WAIT_TIME)
            logging.info("Ù…Ø±ÙˆØ±Ú¯Ø± Chrome Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯ (Ø¯Ø± Ø­Ø§Ù„Øª Headless).")
        except WebDriverException as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ ChromeDriver: {e}")
            logging.error("Ù„Ø·ÙØ§Ù‹ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ ChromeDriver Ù†ØµØ¨ Ø´Ø¯Ù‡ Ùˆ Ø¯Ø± PATH Ø³ÛŒØ³ØªÙ… Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ø¯ØŒ ÛŒØ§ Ù…Ø³ÛŒØ± Ø¢Ù† Ø¨Ù‡ Ø¯Ø±Ø³ØªÛŒ Ø¯Ø± CHROME_DRIVER_PATH Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡ Ø§Ø³Øª.")
            logging.error("Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø¢Ø®Ø±ÛŒÙ† Ù†Ø³Ø®Ù‡ ChromeDriver Ø±Ø§ Ø§Ø² https://chromedriver.chromium.org/downloads Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯.")
            logging.error("Ù‡Ù…Ú†Ù†ÛŒÙ†ØŒ Ø§Ú¯Ø± Ø§Ø² Selenium Ù†Ø³Ø®Ù‡ Û´.Û¶ Ø¨Ù‡ Ø¨Ø§Ù„Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒØ¯ØŒ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø®ÙˆØ¯Ø´ Ø¢Ù† Ø±Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ù†Ø¯ Ø§Ú¯Ø± Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ù„Ø§Ø²Ù… Ù†ØµØ¨ Ø¨Ø§Ø´Ù†Ø¯.")
            raise  # Ø®Ø·Ø§ Ø±Ø§ Ù…Ø¬Ø¯Ø¯Ø§ Ù¾Ø±ØªØ§Ø¨ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… ØªØ§ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù…ØªÙˆÙ‚Ù Ø´ÙˆØ¯

    def _normalize_url(self, url_string):
        """ URL Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ù‡ØªØ±ØŒ Ù†Ø±Ù…Ø§Ù„ Ùˆ Ø¯Ø§Ù…Ù†Ù‡ Ø§ØµÙ„ÛŒ Ø¢Ù† Ø±Ø§ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. """
        if not url_string: return ""
        try:
            parsed_url = urllib.parse.urlparse(url_string)
            domain = parsed_url.netloc.lower().replace("www.", "")
            return domain
        except Exception:
            return "" # Ø¯Ø± ØµÙˆØ±Øª Ø¨Ø±ÙˆØ² Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø§Ø±Ø³ URL

    def _handle_cookie_consent(self, wait):
        """ ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ù¾Ø°ÛŒØ±Ø´ ÛŒØ§ Ø±Ø¯ Ú©Ø±Ø¯Ù† Ù¾Ø§Ù¾â€ŒØ¢Ù¾ Ú©ÙˆÚ©ÛŒâ€ŒÙ‡Ø§. """
        consent_selectors = [
            "//button[.//div[contains(text(),'Accept all')]]",
            "//button[.//div[contains(text(),'Reject all')]]", # Ú¯Ø§Ù‡ÛŒ Ú¯Ø²ÛŒÙ†Ù‡ Ø±Ø¯ Ú©Ø±Ø¯Ù† Ù‡Ù… ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ Ùˆ Ø¨Ù‡ØªØ± Ø§Ø³Øª
            "//button[@id='L2AGLb']", # Ù…Ø¹Ù…ÙˆÙ„Ø§ Accept
            "//button[@id='W0wltc']", # Ù…Ø¹Ù…ÙˆÙ„Ø§ Reject
            "//div[text()='I agree']",
            "//button[contains(., 'Agree') or contains(., 'Accept')]", # Ø¹Ù…ÙˆÙ…ÛŒ ØªØ±
        ]
        for selector in consent_selectors:
            try:
                consent_button = wait.until(EC.element_to_be_clickable((By.XPATH, selector)))
                consent_button.click()
                logging.info(f"Ø¯Ú©Ù…Ù‡ Ú©ÙˆÚ©ÛŒ Ø¨Ø§ Ø³Ù„Ú©ØªÙˆØ± '{selector}' Ú©Ù„ÛŒÚ© Ø´Ø¯.")
                time.sleep(0.5) # Ú©Ù…ÛŒ ØµØ¨Ø± Ø¨Ø±Ø§ÛŒ Ø§Ø¹Ù…Ø§Ù„
                return True
            except TimeoutException:
                continue
        logging.info("Ù¾Ø§Ù¾â€ŒØ¢Ù¾ Ú©ÙˆÚ©ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯ ÛŒØ§ Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ Ù…Ø¯ÛŒØ±ÛŒØª Ø¢Ù† Ù†Ø¨ÙˆØ¯.")
        return False

    def _extract_search_results(self):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†ØªØ§ÛŒØ¬ Ø¬Ø³ØªØ¬Ùˆ Ø§Ø² ØµÙØ­Ù‡ ÙØ¹Ù„ÛŒ."""
        # Ø³Ù„Ú©ØªÙˆØ±Ù‡Ø§ÛŒ Ø±Ø§ÛŒØ¬ Ø¨Ø±Ø§ÛŒ Ø¨Ù„Ø§Ú©â€ŒÙ‡Ø§ÛŒ Ù†ØªØ§ÛŒØ¬ Ø§ØµÙ„ÛŒ Ú¯ÙˆÚ¯Ù„. Ø§ÛŒÙ†â€ŒÙ‡Ø§ Ù…Ù…Ú©Ù† Ø§Ø³Øª ØªØºÛŒÛŒØ± Ú©Ù†Ù†Ø¯.
        # Ø§ÙˆÙ„ÙˆÛŒØª Ø¨Ø§ Ø³Ù„Ú©ØªÙˆØ±Ù‡Ø§ÛŒÛŒ Ø§Ø³Øª Ú©Ù‡ Ù…Ø³ØªÙ‚ÛŒÙ…Ø§ Ù„ÛŒÙ†Ú© Ø§ØµÙ„ÛŒ Ø±Ø§ Ù‡Ø¯Ù Ù‚Ø±Ø§Ø± Ù…ÛŒâ€ŒØ¯Ù‡Ù†Ø¯.
        # Ø³Ù„Ú©ØªÙˆØ± ".yuRUbf > a" Ø¨Ø±Ø§ÛŒ Ù†ØªØ§ÛŒØ¬ Ø§Ø±Ú¯Ø§Ù†ÛŒÚ© Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ø¨Ø³ÛŒØ§Ø± Ø±Ø§ÛŒØ¬ Ø¨ÙˆØ¯Ù‡ Ø§Ø³Øª.
        # Ø³Ù„Ú©ØªÙˆØ± "div.g a h3" Ù†ÛŒØ² Ø§ØºÙ„Ø¨ Ø¹Ù†ÙˆØ§Ù†â€ŒÙ‡Ø§ Ø±Ø§ Ø¯Ø± Ø¨Ø± Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯.
        # Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ù…Ø§ Ø¨Ù‡ Ø¯Ù†Ø¨Ø§Ù„ Ø®ÙˆØ¯ ØªÚ¯ <a> Ú©Ù‡ Ø¯Ø§Ø±Ø§ÛŒ href Ø§Ø³Øª Ù‡Ø³ØªÛŒÙ….
        result_selectors = [
            "div.g .yuRUbf > a",                            # Ø±Ø§ÛŒØ¬ ØªØ±ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ù†ØªØ§ÛŒØ¬ Ø§Ø±Ú¯Ø§Ù†ÛŒÚ©
            "div.g div[role='link']",                       # Ú¯Ø§Ù‡ÛŒ Ø§ÙˆÙ‚Ø§Øª Ù„ÛŒÙ†Ú© Ù‡Ø§ Ø¯Ø± Ø§ÛŒÙ† Ø³Ø§Ø®ØªØ§Ø± Ù‡Ø³ØªÙ†Ø¯
            "div.hlcw0c .yuRUbf > a",                       # Ø³Ø§Ø®ØªØ§Ø± Ø¯ÛŒÚ¯Ø±
            "div.Gx5Zad.fP1Qef.xpd.ETM_NB .kCrYT a",        # Ø³Ø§Ø®ØªØ§Ø± Ù¾ÛŒÚ†ÛŒØ¯Ù‡ ØªØ±
            "//div[contains(@class, 'g ')]//a[@data-ved and @href and not(contains(@class, 'fl')) and count(h3)>0]" # XPath Ø§Ù†Ø¹Ø·Ø§Ùâ€ŒÙ¾Ø°ÛŒØ±ØªØ±
        ]
        
        all_links_in_page = []
        for selector in result_selectors:
            try:
                elements = self.driver.find_elements(By.CSS_SELECTOR if not selector.startswith("//") else By.XPATH, selector)
                if elements:
                    for elem in elements:
                        href = elem.get_attribute("href")
                        # Ø¯Ø±ÛŒØ§ÙØª Ø¹Ù†ÙˆØ§Ù† Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØªØ± Ø´ÙˆØ¯ØŒ Ú¯Ø§Ù‡ÛŒ h3 ÙØ±Ø²Ù†Ø¯ Ù…Ø³ØªÙ‚ÛŒÙ… a Ù†ÛŒØ³Øª
                        title = ""
                        try:
                            # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ ÛŒØ§ÙØªÙ† h3 Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ù„ÛŒÙ†Ú©
                            h3_element = elem.find_element(By.XPATH, ".//h3")
                            title = h3_element.text.strip()
                        except NoSuchElementException:
                            # Ø§Ú¯Ø± h3 Ù…Ø³ØªÙ‚ÛŒÙ… Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯ØŒ Ø³Ø¹ÛŒ Ø¯Ø± ÛŒØ§ÙØªÙ† Ø§Ø² Ø³Ø§Ø®ØªØ§Ø±Ù‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø±
                            try:
                                parent_with_h3 = elem.find_element(By.XPATH, "./ancestor::div[.//h3][1]")
                                title = parent_with_h3.find_element(By.XPATH, ".//h3").text.strip()
                            except NoSuchElementException:
                                title = "Ø¹Ù†ÙˆØ§Ù† ÛŒØ§ÙØª Ù†Ø´Ø¯"
                        
                        if href: # ÙÙ‚Ø· Ù„ÛŒÙ†Ú© Ù‡Ø§ÛŒ Ù…Ø¹ØªØ¨Ø±
                           all_links_in_page.append({"url": href, "title": title})
                    if all_links_in_page:
                        # logging.debug(f"Ø¨Ø§ Ø³Ù„Ú©ØªÙˆØ± '{selector}' ØªØ¹Ø¯Ø§Ø¯ {len(all_links_in_page)} Ù„ÛŒÙ†Ú© ÛŒØ§ÙØª Ø´Ø¯.")
                        return all_links_in_page # Ø¨Ø§ Ø§ÙˆÙ„ÛŒÙ† Ø³Ù„Ú©ØªÙˆØ± Ù…ÙˆÙÙ‚ØŒ Ø®Ø§Ø±Ø¬ Ù…ÛŒâ€ŒØ´ÙˆÛŒÙ…
            except Exception as e:
                logging.debug(f"Ø®Ø·Ø§ ÛŒØ§ Ø¹Ø¯Ù… ÛŒØ§ÙØªÙ† Ù†ØªÛŒØ¬Ù‡ Ø¨Ø§ Ø³Ù„Ú©ØªÙˆØ± '{selector}': {e}")
                continue
        
        if not all_links_in_page:
             logging.warning("Ù‡ÛŒÚ† Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ Ø¨Ø§ Ø³Ù„Ú©ØªÙˆØ±Ù‡Ø§ÛŒ ØªØ¹Ø±ÛŒÙ Ø´Ø¯Ù‡ Ø¯Ø± Ø§ÛŒÙ† ØµÙØ­Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        return all_links_in_page

    def _click_next_page(self, wait):
        """ ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ú©Ù„ÛŒÚ© Ø±ÙˆÛŒ Ø¯Ú©Ù…Ù‡ 'ØµÙØ­Ù‡ Ø¨Ø¹Ø¯'. """
        next_page_selectors = [
            "//a[@id='pnnext']",
            "//a[@aria-label='Next page']",
            "//a[@aria-label='Page suivante']", # Ø¨Ø±Ø§ÛŒ Ø²Ø¨Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø±
            "//span[text()='Next']/parent::a",
            "//span[text()='Ø¨Ø¹Ø¯ÛŒ']/parent::a"
        ]
        for selector in next_page_selectors:
            try:
                next_button = wait.until(EC.element_to_be_clickable((By.XPATH, selector)))
                # self.driver.execute_script("arguments[0].scrollIntoView(true);", next_button) # Ø§Ø³Ú©Ø±ÙˆÙ„ Ø¨Ù‡ Ø¯Ú©Ù…Ù‡ Ø§Ú¯Ø± Ù„Ø§Ø²Ù… Ø¨Ø§Ø´Ø¯
                # time.sleep(0.3)
                next_button.click()
                logging.info(f"Ø¨Ù‡ ØµÙØ­Ù‡ Ø¨Ø¹Ø¯ Ø±ÙØªÛŒÙ… (Ø¨Ø§ Ø³Ù„Ú©ØªÙˆØ± '{selector}').")
                return True
            except TimeoutException:
                continue
        logging.warning("Ø¯Ú©Ù…Ù‡ 'ØµÙØ­Ù‡ Ø¨Ø¹Ø¯' Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
        return False

    def _check_for_captcha(self):
        """Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ú©Ù¾Ú†Ø§ Ø¯Ø± ØµÙØ­Ù‡."""
        # Ø§ÛŒÙ† ÛŒÚ© Ø±ÙˆØ´ Ø³Ø§Ø¯Ù‡ Ø§Ø³Øª Ùˆ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø±Ø§ÛŒ Ø§Ù†ÙˆØ§Ø¹ Ú©Ù¾Ú†Ø§Ù‡Ø§ Ú©Ø§ÙÛŒ Ù†Ø¨Ø§Ø´Ø¯.
        captcha_indicators = [
            "//iframe[contains(@src, 'recaptcha')]",
            "//div[text()='reCAPTCHA']",
            "//form[@id='captcha-form']",
            "//h1[contains(text(),'unusual traffic')]",
            "//p[contains(text(),'systems have detected unusual traffic')]"
        ]
        for indicator in captcha_indicators:
            try:
                if self.driver.find_elements(By.XPATH, indicator):
                    logging.error("Ú©Ù¾Ú†Ø§ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯!")
                    if TAKE_SCREENSHOTS_ON_ERROR:
                        filename = f"captcha_detected_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
                        self.driver.save_screenshot(filename)
                        logging.info(f"Ø§Ø³Ú©Ø±ÛŒÙ†â€ŒØ´Ø§Øª Ú©Ù¾Ú†Ø§ Ø¯Ø± '{filename}' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")
                    return True
            except Exception: # Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø®ÙˆØ¯ find_elements Ø®Ø·Ø§ Ø¨Ø¯Ù‡Ø¯
                continue
        return False


    def get_rank_for_keyword(self, keyword, max_pages=3, retries=1):
        """
        Ø±ØªØ¨Ù‡ Ø¯Ø§Ù…Ù†Ù‡ Ù‡Ø¯Ù Ø±Ø§ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ Ø®Ø§Øµ Ø¬Ø³ØªØ¬Ùˆ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
        Ø¯Ø± ØµÙˆØ±Øª Ø¨Ø±ÙˆØ² Ø®Ø·Ø§ØŒ ØªØ§ ØªØ¹Ø¯Ø§Ø¯ retries ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.
        """
        if not self.driver:
            logging.error("Ø¯Ø±Ø§ÛŒÙˆØ± Ù…Ø±ÙˆØ±Ú¯Ø± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø¬Ø³ØªØ¬Ùˆ Ú©Ø±Ø¯.")
            return {"keyword": keyword, "rank": "Error - Driver not initialized", "url": "", "title": "", "page": 0, "status": "Error"}

        attempt = 0
        while attempt <= retries:
            if attempt > 0:
                logging.info(f"ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ ({attempt}/{retries}) Ø¨Ø±Ø§ÛŒ Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ '{keyword}' Ù¾Ø³ Ø§Ø² Ú†Ù†Ø¯ Ø«Ø§Ù†ÛŒÙ‡...")
                time.sleep(random.uniform(10, 20) * attempt) # ØªØ§Ø®ÛŒØ± Ø¨ÛŒØ´ØªØ± Ø¯Ø± Ù‡Ø± ØªÙ„Ø§Ø´

            try:
                logging.info(f"ğŸ” Ø¯Ø± Ø­Ø§Ù„ Ø¬Ø³ØªØ¬ÙˆÛŒ Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ: '{keyword}' (ØªÙ„Ø§Ø´ {attempt+1})")
                # Ù¾Ø§Ø±Ø§Ù…ØªØ± num=100 Ø¨Ø±Ø§ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Û±Û°Û° Ù†ØªÛŒØ¬Ù‡ (Ú¯ÙˆÚ¯Ù„ ØªØµÙ…ÛŒÙ… Ù†Ù‡Ø§ÛŒÛŒ Ø±Ø§ Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯)
                # Ù¾Ø§Ø±Ø§Ù…ØªØ± gl Ùˆ hl Ø¨Ø±Ø§ÛŒ ØªØ¹ÛŒÛŒÙ† Ú©Ø´ÙˆØ± Ùˆ Ø²Ø¨Ø§Ù† Ù†ØªØ§ÛŒØ¬ Ø¨Ø±Ø§ÛŒ ÛŒÚ©Ù†ÙˆØ§Ø®ØªÛŒ
                # Ù…Ù…Ú©Ù† Ø§Ø³Øª Ú¯ÙˆÚ¯Ù„ Ø§ÛŒÙ† Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ Ø±Ø§ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ø¨Ú¯ÛŒØ±Ø¯ ÛŒØ§ Ø±ÙØªØ§Ø± Ù…ØªÙØ§ÙˆØªÛŒ Ù†Ø´Ø§Ù† Ø¯Ù‡Ø¯.
                search_url = f"https://www.google.com/search?q={urllib.parse.quote_plus(keyword)}&num={RESULTS_PER_PAGE_ESTIMATE * max_pages}&hl=en&gl=us"
                self.driver.get(search_url)
                
                wait = WebDriverWait(self.driver, EXPLICIT_WAIT_TIME)
                
                # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù¾Ú†Ø§ Ø¨Ù„Ø§ÙØ§ØµÙ„Ù‡ Ù¾Ø³ Ø§Ø² Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØµÙØ­Ù‡
                if self._check_for_captcha():
                    # Ø§Ú¯Ø± Ø¯Ø± ØªÙ„Ø§Ø´ Ø§ÙˆÙ„ Ú©Ù¾Ú†Ø§ Ø¨ÙˆØ¯ØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù† ØªÙ„Ø§Ø´â€ŒÙ‡Ø§ÛŒ Ø¨Ø¹Ø¯ÛŒ Ø±Ø§ Ù…ØªÙˆÙ‚Ù Ú©Ø±Ø¯
                    # Ù…Ú¯Ø± Ø§ÛŒÙ†Ú©Ù‡ Ø¨Ø®ÙˆØ§Ù‡ÛŒÙ… Ø¨Ø§ Ø³Ø´Ù† Ø¬Ø¯ÛŒØ¯ ÛŒØ§ Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø¯ÛŒÚ¯Ø± ØªÙ„Ø§Ø´ Ú©Ù†ÛŒÙ… (Ù…Ù†Ø·Ù‚ Ù¾ÛŒÚ†ÛŒØ¯Ù‡â€ŒØªØ±)
                    if attempt == 0 : # ÙÙ‚Ø· Ø¯Ø± ØªÙ„Ø§Ø´ Ø§ÙˆÙ„ Ø§Ú¯Ø± Ú©Ù¾Ú†Ø§ Ø¨ÙˆØ¯ Ø³Ø±ÛŒØ¹Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†
                         return {"keyword": keyword, "rank": "CAPTCHA", "url": "", "title": "", "page": 0, "status": "CAPTCHA"}
                    # Ø§Ú¯Ø± Ø¯Ø± ØªÙ„Ø§Ø´ Ù‡Ø§ÛŒ Ø¨Ø¹Ø¯ÛŒ Ø¨ÙˆØ¯ØŒ Ø´Ø§ÛŒØ¯ Ù…Ø´Ú©Ù„ Ù…ÙˆÙ‚ØªÛŒ Ø¨ÙˆØ¯Ù‡
                    # ÙØ¹Ù„Ø§ Ø¨Ø§ Ø§Ø¯Ø§Ù…Ù‡ Ø¯Ø§Ø¯Ù† Ø¨Ù‡ ØªÙ„Ø§Ø´ Ø¨Ø¹Ø¯ÛŒ Ø±ÛŒØ³Ú© Ù…ÛŒÚ©Ù†ÛŒÙ…

                self._handle_cookie_consent(wait) # Ù…Ø¯ÛŒØ±ÛŒØª Ù¾Ø§Ù¾ Ø¢Ù¾ Ú©ÙˆÚ©ÛŒ
                
                # Ù…Ù†ØªØ¸Ø± Ù…Ø§Ù†Ø¯Ù† Ø¨Ø±Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ† Ù†ØªÛŒØ¬Ù‡ Ø¬Ø³ØªØ¬Ùˆ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù†Ø´Ø§Ù†Ù‡ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØµÙØ­Ù‡
                WebDriverWait(self.driver, EXPLICIT_WAIT_TIME).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, "div.g, div.hlcw0c, div.Gx5Zad")) 
                )
                time.sleep(random.uniform(1,2)) # Ú©Ù…ÛŒ ØµØ¨Ø± Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ø§Ù…Ù„ Ø§ÙˆÙ„ÛŒÙ‡

                absolute_rank_counter = 0
                for page_num in range(1, max_pages + 1):
                    logging.info(f"---- Ø¨Ø±Ø±Ø³ÛŒ ØµÙØ­Ù‡ {page_num} Ù†ØªØ§ÛŒØ¬ Ø¨Ø±Ø§ÛŒ '{keyword}' ----")
                    
                    if self._check_for_captcha(): # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù¾Ú†Ø§ Ù‚Ø¨Ù„ Ø§Ø² Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†ØªØ§ÛŒØ¬ Ù‡Ø± ØµÙØ­Ù‡
                         return {"keyword": keyword, "rank": "CAPTCHA", "url": "", "title": "", "page": page_num, "status": "CAPTCHA"}

                    page_results = self._extract_search_results()
                    if not page_results:
                        logging.warning(f"Ù‡ÛŒÚ† Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ Ø¯Ø± ØµÙØ­Ù‡ {page_num} Ø¨Ø±Ø§ÛŒ '{keyword}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                        # Ø´Ø§ÛŒØ¯ Ù„Ø§Ø²Ù… Ø¨Ø§Ø´Ø¯ Ø¨Ù‡ ØµÙØ­Ù‡ Ø¨Ø¹Ø¯ Ø¨Ø±ÙˆÛŒÙ… ÛŒØ§ Ø¬Ø³ØªØ¬Ùˆ Ø±Ø§ Ù…ØªÙˆÙ‚Ù Ú©Ù†ÛŒÙ…
                        # ÙØ¹Ù„Ø§ Ø§Ø¯Ø§Ù…Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ… Ø´Ø§ÛŒØ¯ Ø¯Ø± ØµÙØ­Ø§Øª Ø¨Ø¹Ø¯ÛŒ Ù†ØªÛŒØ¬Ù‡ Ø¨Ø§Ø´Ø¯.

                    for result_item in page_results:
                        absolute_rank_counter += 1
                        link_domain = self._normalize_url(result_item.get("url"))
                        
                        # logging.debug(f"Ø±ØªØ¨Ù‡ {absolute_rank_counter}: {result_item.get('url')} (Ø¯Ø§Ù…Ù†Ù‡ Ù†Ø±Ù…Ø§Ù„ Ø´Ø¯Ù‡: {link_domain})")

                        if self.target_domain in link_domain:
                            logging.info(f"ğŸ‰ Ø¯Ø§Ù…Ù†Ù‡ '{self.target_domain}' Ø¨Ø±Ø§ÛŒ '{keyword}' Ù¾ÛŒØ¯Ø§ Ø´Ø¯!")
                            logging.info(f"Ø±ØªØ¨Ù‡: {absolute_rank_counter}, Ø¹Ù†ÙˆØ§Ù†: '{result_item.get('title')}', URL: {result_item.get('url')}")
                            return {"keyword": keyword, "rank": absolute_rank_counter, "url": result_item.get("url"), 
                                    "title": result_item.get("title"), "page": page_num, "status": "Found"}
                    
                    # Ø±ÙØªÙ† Ø¨Ù‡ ØµÙØ­Ù‡ Ø¨Ø¹Ø¯ (Ø§Ú¯Ø± Ù‡Ù†ÙˆØ² Ø¯Ø§Ù…Ù†Ù‡ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯Ù‡ Ùˆ Ø¢Ø®Ø±ÛŒÙ† ØµÙØ­Ù‡ Ù†ÛŒØ³Øª)
                    if page_num < max_pages:
                        logging.debug(f"Ø¯Ø§Ù…Ù†Ù‡ Ù‡Ø¯Ù Ø¯Ø± ØµÙØ­Ù‡ {page_num} ÛŒØ§ÙØª Ù†Ø´Ø¯ØŒ ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø±ÙØªÙ† Ø¨Ù‡ ØµÙØ­Ù‡ Ø¨Ø¹Ø¯...")
                        if self._click_next_page(wait):
                            time.sleep(random.uniform(RANDOM_DELAY_BETWEEN_PAGES[0], RANDOM_DELAY_BETWEEN_PAGES[1]))
                        else:
                            logging.info(f"Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø¨Ù‡ ØµÙØ­Ù‡ Ø¨Ø¹Ø¯ Ø§Ø² {page_num} Ø¨Ø±Ø§ÛŒ '{keyword}' Ø±ÙØª. Ù¾Ø§ÛŒØ§Ù† Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ú©Ù„Ù…Ù‡.")
                            break # Ø§Ø² Ø­Ù„Ù‚Ù‡ ØµÙØ­Ø§Øª Ø®Ø§Ø±Ø¬ Ø´ÙˆØŒ Ú†ÙˆÙ† Ø¯Ú©Ù…Ù‡ Ø¨Ø¹Ø¯ÛŒ Ù†ÛŒØ³Øª
                    else:
                        logging.info(f"Ø¨Ù‡ Ø­Ø¯Ø§Ú©Ø«Ø± ØªØ¹Ø¯Ø§Ø¯ ØµÙØ­Ø§Øª ({max_pages}) Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ '{keyword}' Ø±Ø³ÛŒØ¯ÛŒÙ….")

                logging.info(f"Ø¯Ø§Ù…Ù†Ù‡ '{self.target_domain}' Ø¨Ø±Ø§ÛŒ '{keyword}' Ø¯Ø± {max_pages} ØµÙØ­Ù‡ Ø§ÙˆÙ„ ({absolute_rank_counter} Ù†ØªÛŒØ¬Ù‡ Ø¨Ø±Ø±Ø³ÛŒ Ø´Ø¯Ù‡) ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                return {"keyword": keyword, "rank": f"Not Found in top {absolute_rank_counter}", "url": "", "title": "", "page": max_pages, "status": "Not Found"}

            except TimeoutException as e:
                logging.warning(f"Timeout Ø¯Ø± ØªÙ„Ø§Ø´ {attempt + 1} Ø¨Ø±Ø§ÛŒ '{keyword}': {e}")
                if TAKE_SCREENSHOTS_ON_ERROR: self.driver.save_screenshot(f"error_timeout_{keyword.replace(' ','_')}_{attempt}.png")
                if attempt >= retries: 
                    return {"keyword": keyword, "rank": "Error - Timeout", "url": "", "title": "", "page": 0, "status": "Error"}
            except WebDriverException as e: # Ø®Ø·Ø§Ù‡Ø§ÛŒ Ø¹Ù…ÙˆÙ…ÛŒâ€ŒØªØ± Ø¯Ø±Ø§ÛŒÙˆØ±
                logging.error(f"Ø®Ø·Ø§ÛŒ WebDriver Ø¯Ø± ØªÙ„Ø§Ø´ {attempt + 1} Ø¨Ø±Ø§ÛŒ '{keyword}': {type(e).__name__} - {e}")
                if TAKE_SCREENSHOTS_ON_ERROR: self.driver.save_screenshot(f"error_webdriver_{keyword.replace(' ','_')}_{attempt}.png")
                # Ø§Ú¯Ø± Ø®Ø·Ø§ÛŒ session id is null ÛŒØ§ Ù…Ø´Ø§Ø¨Ù‡ Ø¢Ù† Ø¨ÙˆØ¯ØŒ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù…Ø±ÙˆØ±Ú¯Ø± Ú©Ø±Ø´ Ú©Ø±Ø¯Ù‡ Ø¨Ø§Ø´Ø¯.
                if "session id is null" in str(e).lower() or "target window already closed" in str(e).lower():
                    logging.error("Ù…Ø±ÙˆØ±Ú¯Ø± Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ú©Ø±Ø´ Ú©Ø±Ø¯Ù‡ ÛŒØ§ Ø¨Ø³ØªÙ‡ Ø´Ø¯Ù‡ Ø§Ø³Øª. ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù…Ø¬Ø¯Ø¯ Ø¯Ø±Ø§ÛŒÙˆØ±...")
                    self.close() # Ø¨Ø³ØªÙ† Ø¯Ø±Ø§ÛŒÙˆØ± ÙØ¹Ù„ÛŒ (Ø§Ú¯Ø± Ù‡Ù†ÙˆØ² ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯)
                    try:
                        self._setup_driver() # Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù…Ø¬Ø¯Ø¯
                    except Exception as setup_err:
                         logging.critical(f"Ø§Ù…Ú©Ø§Ù† Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù…Ø¬Ø¯Ø¯ Ø¯Ø±Ø§ÛŒÙˆØ± ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯: {setup_err}")
                         # Ø§Ú¯Ø± Ù†ØªÙˆØ§Ù†Ø³ØªÛŒÙ… Ù…Ø¬Ø¯Ø¯Ø§ Ø±Ø§Ù‡ Ø§Ù†Ø¯Ø§Ø²ÛŒ Ú©Ù†ÛŒÙ…ØŒ Ø¨Ø§ÛŒØ¯ Ø§Ø² Ø§ÛŒÙ† Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ ØµØ±ÙÙ†Ø¸Ø± Ú©Ù†ÛŒÙ… ÛŒØ§ Ú©Ù„ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø±Ø§ Ù…ØªÙˆÙ‚Ù Ú©Ù†ÛŒÙ….
                         return {"keyword": keyword, "rank": "Error - Driver Crash, Restart Failed", "url": "", "title": "", "page": 0, "status": "Error"}
                if attempt >= retries:
                    return {"keyword": keyword, "rank": f"Error - WebDriver ({type(e).__name__})", "url": "", "title": "", "page": 0, "status": "Error"}
            except Exception as e:
                logging.error(f"ÛŒÚ© Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¯Ø± ØªÙ„Ø§Ø´ {attempt + 1} Ø¨Ø±Ø§ÛŒ '{keyword}': {type(e).__name__} - {e}", exc_info=False)
                if TAKE_SCREENSHOTS_ON_ERROR and self.driver:
                     try: self.driver.save_screenshot(f"error_unexpected_{keyword.replace(' ','_')}_{attempt}.png")
                     except: pass
                if attempt >= retries:
                    return {"keyword": keyword, "rank": f"Error - Unexpected ({type(e).__name__})", "url": "", "title": "", "page": 0, "status": "Error"}
            attempt += 1
        
        # Ø§Ú¯Ø± Ø­Ù„Ù‚Ù‡ ØªÙ…Ø§Ù… Ø´Ø¯ Ùˆ Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ù†Ú¯Ø´Øª (Ù†Ø¨Ø§ÛŒØ¯ Ø§ØªÙØ§Ù‚ Ø¨ÛŒÙØªØ¯ Ø§Ú¯Ø± Ù…Ù†Ø·Ù‚ Ø¯Ø±Ø³Øª Ø¨Ø§Ø´Ø¯)
        return {"keyword": keyword, "rank": "Error - Max Retries Reached (Logic Error?)", "url": "", "title": "", "page": 0, "status": "Error"}


    def close(self):
        """Ù…Ø±ÙˆØ±Ú¯Ø± Ø±Ø§ Ù…ÛŒâ€ŒØ¨Ù†Ø¯Ø¯."""
        if self.driver:
            try:
                self.driver.quit()
                logging.info("Ù…Ø±ÙˆØ±Ú¯Ø± Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø³ØªÙ‡ Ø´Ø¯.")
            except Exception as e:
                logging.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø³ØªÙ† Ù…Ø±ÙˆØ±Ú¯Ø±: {e}")
            self.driver = None

def save_results_to_files(results_df, base_filename_prefix):
    """Ù†ØªØ§ÛŒØ¬ DataFrame Ø±Ø§ Ø¯Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ CSV Ùˆ Excel Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    if results_df.empty:
        logging.info("Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
        return

    timestamp_str = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Û±. Ø°Ø®ÛŒØ±Ù‡ Ø¨Ù‡ ØµÙˆØ±Øª ÙØ§ÛŒÙ„ CSV
    csv_filename = f"{base_filename_prefix}_{timestamp_str}.csv"
    try:
        results_df.to_csv(csv_filename, index=False, encoding='utf-8-sig')
        logging.info(f"Ù†ØªØ§ÛŒØ¬ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø± ÙØ§ÛŒÙ„ CSV Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {csv_filename}")
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ CSV '{csv_filename}': {e}")

    # Û². Ø°Ø®ÛŒØ±Ù‡ Ø¨Ù‡ ØµÙˆØ±Øª ÙØ§ÛŒÙ„ Excel (Ù†ÛŒØ§Ø² Ø¨Ù‡ openpyxl: pip install openpyxl)
    excel_filename = f"{base_filename_prefix}_{timestamp_str}.xlsx"
    try:
        results_df.to_excel(excel_filename, index=False, sheet_name='Rankings')
        logging.info(f"Ù†ØªØ§ÛŒØ¬ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø± ÙØ§ÛŒÙ„ Excel Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {excel_filename}")
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ Excel '{excel_filename}': {e}")
        logging.warning("Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ÙØ±Ù…Øª ExcelØŒ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ 'openpyxl' Ø¨Ø§ÛŒØ¯ Ù†ØµØ¨ Ø¨Ø§Ø´Ø¯: `pip install openpyxl`")


if __name__ == "__main__":
    logging.info("--- Ø±Ø¨Ø§Øª Ø¨Ø±Ø±Ø³ÛŒ Ø±ØªØ¨Ù‡ Ú¯ÙˆÚ¯Ù„ Ø³Ø¬Ø§Ø¯ Ø§Ú©Ø¨Ø±ÛŒ ---")
    logging.info(f"Ø¯Ø§Ù…Ù†Ù‡ Ù‡Ø¯Ù: {TARGET_DOMAIN}")
    logging.info(f"ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ: {len(KEYWORDS_TO_TRACK)}")
    logging.info(f"Ø­Ø¯Ø§Ú©Ø«Ø± ØµÙØ­Ø§Øª Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ø± Ú©Ù„Ù…Ù‡: {MAX_PAGES_TO_CHECK}")

    all_results_data = []
    tracker_instance = None

    try:
        tracker_instance = GoogleRankTracker(driver_path=CHROME_DRIVER_PATH, 
                                             target_domain=TARGET_DOMAIN)
        
        for i, keyword in enumerate(KEYWORDS_TO_TRACK):
            result = tracker_instance.get_rank_for_keyword(keyword, max_pages=MAX_PAGES_TO_CHECK, retries=1)
            result['timestamp_executed'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            result['target_domain_checked'] = TARGET_DOMAIN # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¯Ø§Ù…Ù†Ù‡ Ø¨Ø±Ø§ÛŒ ÙˆØ¶ÙˆØ­ Ø¯Ø± Ø®Ø±ÙˆØ¬ÛŒ
            all_results_data.append(result)
            
            logging.info(f"Ù†ØªÛŒØ¬Ù‡ Ø¨Ø±Ø§ÛŒ '{keyword}': Ø±ØªØ¨Ù‡ {result.get('rank', 'N/A')}, ÙˆØ¶Ø¹ÛŒØª: {result.get('status', 'N/A')}")

            # ØªØ§Ø®ÛŒØ± Ø¨ÛŒÙ† Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø¨Ù„Ø§Ú© Ø´Ø¯Ù† (Ù…Ú¯Ø± Ø§ÛŒÙ†Ú©Ù‡ Ø¢Ø®Ø±ÛŒÙ† Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø§Ø´Ø¯)
            if i < len(KEYWORDS_TO_TRACK) - 1:
                delay = random.uniform(RANDOM_DELAY_BETWEEN_KEYWORDS[0], RANDOM_DELAY_BETWEEN_KEYWORDS[1])
                logging.info(f"ØªØ§Ø®ÛŒØ± {delay:.2f} Ø«Ø§Ù†ÛŒÙ‡â€ŒØ§ÛŒ Ù‚Ø¨Ù„ Ø§Ø² Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø¹Ø¯ÛŒ...")
                time.sleep(delay)

    except KeyboardInterrupt: # Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ctrl+C Ø¨Ø²Ù†Ø¯
        logging.warning("Ø¹Ù…Ù„ÛŒØ§Øª ØªÙˆØ³Ø· Ú©Ø§Ø±Ø¨Ø± Ù…ØªÙˆÙ‚Ù Ø´Ø¯.")
    except WebDriverException as e: # Ø®Ø·Ø§Ù‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø¯Ø±Ø§ÛŒÙˆØ± Ú©Ù‡ Ø¯Ø± init Ø±Ø® Ù…ÛŒâ€ŒØ¯Ù‡Ø¯
        logging.critical(f"Ø§Ù…Ú©Ø§Ù† Ø§Ø¯Ø§Ù…Ù‡ Ú©Ø§Ø± Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø®Ø·Ø§ÛŒ WebDriver ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯: {e}")
    except Exception as e:
        logging.critical(f"ÛŒÚ© Ø®Ø·Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†Ø´Ø¯Ù‡ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Ø§ØµÙ„ÛŒ Ø±Ø® Ø¯Ø§Ø¯: {e}", exc_info=True)
    finally:
        if tracker_instance:
            tracker_instance.close()
        
        logging.info("\n--- Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬ ---")
        if all_results_data:
            results_df = pd.DataFrame(all_results_data)
            # ØªÙ†Ø¸ÛŒÙ… ØªØ±ØªÛŒØ¨ Ø³ØªÙˆÙ† Ù‡Ø§ Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ Ø¨Ù‡ØªØ±
            column_order = ['timestamp_executed', 'keyword', 'target_domain_checked', 'rank', 'status', 'url', 'title', 'page']
            # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø§ÛŒÙ†Ú©Ù‡ Ù‡Ù…Ù‡ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ù†Ø¯ØŒ Ø§Ú¯Ø± Ù†Ù‡ Ø¨Ø§ Ø®Ø§Ù„ÛŒ Ù¾Ø± Ø´ÙˆÙ†Ø¯
            results_df = results_df.reindex(columns=column_order, fill_value='')
            
            # Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬ Ø¯Ø± Ú©Ù†Ø³ÙˆÙ„ (Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø±Ø§ Ø¨Ø±Ø§ÛŒ ØªØ¹Ø¯Ø§Ø¯ Ø²ÛŒØ§Ø¯ Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ Ø®Ù„Ø§ØµÙ‡ ØªØ± Ú©Ø±Ø¯)
            # pd.set_option('display.max_rows', None)
            # pd.set_option('display.max_colwidth', None)
            # pd.set_option('display.width', 1000)
            logging.info(f"\n{results_df.to_string(index=False)}")
            
            # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ Ø¯Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
            save_results_to_files(results_df, OUTPUT_FILENAME_PREFIX)

        else:
            logging.info("Ù‡ÛŒÚ† Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù†Ø´Ø¯.")
        
        logging.info("--- Ù¾Ø§ÛŒØ§Ù† Ø¹Ù…Ù„ÛŒØ§Øª Ø±Ø¨Ø§Øª ---")
